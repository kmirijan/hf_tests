{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmirijan/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Pipeline Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 629/629 [00:00<00:00, 223kB/s]\n",
      "model.safetensors: 100%|██████████| 268M/268M [00:59<00:00, 4.53MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 26.2kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 300kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455},\n",
       " {'label': 'NEGATIVE', 'score': 0.9993776679039001}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \n",
    "     \"I hate this so much!\",\n",
    "     \"I wish life was better\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 1.15k/1.15k [00:00<00:00, 891kB/s]\n",
      "model.safetensors: 100%|██████████| 1.63G/1.63G [04:11<00:00, 6.48MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 8.58kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:03<00:00, 256kB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:02<00:00, 217kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:03<00:00, 433kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445991277694702, 0.11197404563426971, 0.043426841497421265]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': \"We've just had a bankrupcy and need to file the right form. Can you prepare the documents\",\n",
       " 'labels': ['unknown',\n",
       "  'Security and Exchange Commission Filings',\n",
       "  'Cross Border Import'],\n",
       " 'scores': [0.4292425215244293, 0.3179680407047272, 0.2527894377708435]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This didn't really work\n",
    "# Potentially, a different zero-shot classifer could perform better\n",
    "# Or maybe the labels just aren't good enough\n",
    "classifier(\n",
    "    \"We've just had a bankrupcy and need to file the right form. Can you prepare the documents\",\n",
    "    candidate_labels = [\n",
    "        \"Cross Border Import\",\n",
    "        \"Security and Exchange Commission Filings\",\n",
    "        \"unknown\"\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 665/665 [00:00<00:00, 314kB/s]\n",
      "model.safetensors: 100%|██████████| 548M/548M [01:06<00:00, 8.20MB/s] \n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 10.1kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 848kB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.21MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.22MB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to create, execute and debug the applets.\\n\\nFor an overview of the steps, see Create Applets and Set Up Bootstrap Applets with Custom Bootstrap JS Bootstrap is a pre-'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Here are the necessary documents for importing across the US-Mexico border. You begin by collecting all relevant national identification documents and all relevant federal, state and local law enforcement records that are available for review. Additionally, you must obtain a state-issued certificate'}]\n"
     ]
    }
   ],
   "source": [
    "generated = generator(\"Here are the necessary documents for importing across the US-Mexico border. You begin by collecting\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get more specific on the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 762/762 [00:00<00:00, 356kB/s]\n",
      "model.safetensors: 100%|██████████| 353M/353M [00:52<00:00, 6.78MB/s] \n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 7.29kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 852kB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.99MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.53MB/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Here are the necessary documents for importing across the US-Mexico border. You begin by collecting an ID-C (identification file) in a U.S. passport. You begin by finding an American citizenship card and a State-issued certificate. You are then able to legally import all the documents until their birth certificate is issued.\\n\\n\\n\\n\\n\\nIf you don't have a visa, you must enter the country in a specific language, and you may travel in this country by visiting\"},\n",
       " {'generated_text': 'Here are the necessary documents for importing across the US-Mexico border. You begin by collecting the US Border Patrol numbers (Mexican) and then placing them on the United States-Mexico border. You then find out if you have an email for the \"Immigration and Customs Enforcement \" (ICE) team and send your data using them to the US Border Patrol Bureau.\\n\\nThe \"Immigration and Customs Enforcement\" team\\'s database lets you store some of this information online in your local government.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"Here are the necessary documents for importing across the US-Mexico border. You begin by collecting\",\n",
    "    max_length=100,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 480/480 [00:00<00:00, 225kB/s]\n",
      "model.safetensors: 100%|██████████| 331M/331M [00:51<00:00, 6.47MB/s] \n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "vocab.json: 100%|██████████| 899k/899k [00:01<00:00, 751kB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.12MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.37MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14670738577842712,\n",
       "  'token': 12373,\n",
       "  'token_str': ' passport',\n",
       "  'sequence': 'The first document you need when importing goods is the passport form.'},\n",
       " {'score': 0.09443926811218262,\n",
       "  'token': 8915,\n",
       "  'token_str': ' visa',\n",
       "  'sequence': 'The first document you need when importing goods is the visa form.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"The first document you need when importing goods is the <mask> form.\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 998/998 [00:00<00:00, 583kB/s]\n",
      "model.safetensors: 100%|██████████| 1.33G/1.33G [05:55<00:00, 3.75MB/s]\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "tokenizer_config.json: 100%|██████████| 60.0/60.0 [00:00<00:00, 5.88kB/s]\n",
      "vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 289kB/s]\n",
      "/home/kmirijan/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': 0.9996173,\n",
       "  'word': 'United States',\n",
       "  'start': 65,\n",
       "  'end': 78}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"Prepare the necessary customs documents to import goods into the United States and submit these customs \\\n",
    "    documents to their respective agencies and authorities. The documents are generally for customs and border \\\n",
    "    protection as well as brokers at entry points for these goods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': 0.99963653,\n",
       "  'word': 'United States',\n",
       "  'start': 65,\n",
       "  'end': 78},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.92689705,\n",
       "  'word': 'CBP',\n",
       "  'start': 196,\n",
       "  'end': 199}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"Prepare the necessary customs documents to import goods into the United States and submit these customs documents to their respective agencies and authorities. The documents are generally for the CBP as well as brokers at entry points for these goods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 473/473 [00:00<00:00, 86.2kB/s]\n",
      "model.safetensors: 100%|██████████| 261M/261M [00:33<00:00, 7.71MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 33.3kB/s]\n",
      "vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 304kB/s]\n",
      "tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 1.18MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949766278266907, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 1.97MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.22G/1.22G [02:33<00:00, 7.95MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 29.3kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:01<00:00, 733kB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 5.38MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.42k/1.42k [00:00<00:00, 983kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 301M/301M [00:43<00:00, 6.98MB/s] \n",
      "generation_config.json: 100%|██████████| 293/293 [00:00<00:00, 185kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 42.0/42.0 [00:00<00:00, 38.0kB/s]\n",
      "source.spm: 100%|██████████| 802k/802k [00:01<00:00, 713kB/s]\n",
      "target.spm: 100%|██████████| 778k/778k [00:00<00:00, 3.75MB/s]\n",
      "vocab.json: 100%|██████████| 1.34M/1.34M [00:00<00:00, 4.64MB/s]\n",
      "/home/kmirijan/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
